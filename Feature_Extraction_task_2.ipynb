{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otTOvUXBqAQf",
        "outputId": "323d262f-b084-43ca-ab96-115601142ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-whois\n",
            "  Downloading python_whois-0.9.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tldextract\n",
            "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ipwhois\n",
            "  Downloading ipwhois-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from python-whois) (2.9.0.post0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from tldextract) (3.10)\n",
            "Collecting requests-file>=1.4 (from tldextract)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract) (3.20.0)\n",
            "Collecting dnspython (from ipwhois)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from ipwhois) (0.7.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imagehash) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.16.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->python-whois) (1.17.0)\n",
            "Downloading python_whois-0.9.6-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipwhois-1.3.0-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.7/70.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, requests-file, python-whois, ipwhois, imagehash, tldextract\n",
            "Successfully installed dnspython-2.8.0 imagehash-4.3.2 ipwhois-1.3.0 python-whois-0.9.6 requests-file-2.1.0 tldextract-5.3.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
            "Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.48.1\n"
          ]
        }
      ],
      "source": [
        "# Enhanced Installation Cell\n",
        "!pip install python-whois tldextract ipwhois imagehash pillow requests beautifulsoup4\n",
        "!pip install transformers torch timm sentence-transformers torchvision\n",
        "!pip install accelerate bitsandbytes  # For faster inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Imports\n",
        "import pandas as pd, numpy as np, re, math, hashlib, socket, ssl, io\n",
        "import tldextract\n",
        "from urllib.parse import urlparse, urljoin\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import imagehash\n",
        "from PIL import Image\n",
        "import whois\n",
        "from ipwhois import IPWhois\n",
        "import socket\n",
        "import time\n",
        "\n",
        "# Transformer imports\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoModel, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import timm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "T-sHIUaGqOU-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# üìå DATA COLLECTION (GUARANTEED WORKING)\n",
        "# ==============================\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Starting data collection...\")\n",
        "\n",
        "# Initialize df to avoid NameError\n",
        "df = pd.DataFrame()\n",
        "\n",
        "try:\n",
        "    # User choice\n",
        "    print(\"Choose data source:\")\n",
        "    print(\"1 - Upload files manually\")\n",
        "    print(\"2 - Fetch data automatically from web\")\n",
        "    choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Upload Files\n",
        "        print(\"üìÅ Please upload your CSV or Excel file...\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if uploaded:\n",
        "            for filename in uploaded.keys():\n",
        "                print(f\"Loading: {filename}\")\n",
        "                if filename.endswith(\".csv\"):\n",
        "                    temp_df = pd.read_csv(filename)\n",
        "                elif filename.endswith((\".xls\", \".xlsx\")):\n",
        "                    temp_df = pd.read_excel(filename)\n",
        "                else:\n",
        "                    print(f\"Skipping: {filename}\")\n",
        "                    continue\n",
        "\n",
        "                df = pd.concat([df, temp_df], ignore_index=True)\n",
        "            print(f\"‚úÖ Upload complete. Shape: {df.shape}\")\n",
        "        else:\n",
        "            print(\"‚ùå No files uploaded. Creating empty dataset.\")\n",
        "            df = pd.DataFrame({'url': []})  # Create empty with url column\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        # Fetch from Web\n",
        "        print(\"üåê Fetching data from web...\")\n",
        "\n",
        "        # Phishing URLs\n",
        "        try:\n",
        "            response = requests.get(\"https://openphish.com/feed.txt\", timeout=10)\n",
        "            phishing_urls = response.text.splitlines()[:100]  # First 100 URLs\n",
        "            df_phish = pd.DataFrame(phishing_urls, columns=[\"url\"])\n",
        "            df_phish[\"label\"] = \"phishing\"\n",
        "            print(f\"‚úÖ Phishing URLs: {len(phishing_urls)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to fetch phishing URLs: {e}\")\n",
        "            df_phish = pd.DataFrame(columns=[\"url\", \"label\"])\n",
        "\n",
        "        # Legitimate URLs\n",
        "        try:\n",
        "            response = requests.get(\"https://tranco-list.eu/top-1m.csv\", timeout=10)\n",
        "            lines = response.text.splitlines()[:100]\n",
        "            legit_urls = [line.split(\",\")[1] for line in lines if \",\" in line]\n",
        "            df_legit = pd.DataFrame([\"http://\" + u for u in legit_urls], columns=[\"url\"])\n",
        "            df_legit[\"label\"] = \"legitimate\"\n",
        "            print(f\"‚úÖ Legitimate URLs: {len(legit_urls)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to fetch legitimate URLs: {e}\")\n",
        "            df_legit = pd.DataFrame(columns=[\"url\", \"label\"])\n",
        "\n",
        "        # Combine\n",
        "        df = pd.concat([df_phish, df_legit], ignore_index=True)\n",
        "        print(f\"üåê Web fetch complete. Shape: {df.shape}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice. Creating sample data...\")\n",
        "        # Create sample data as fallback\n",
        "        sample_data = {\n",
        "            'url': [\n",
        "                'https://www.google.com',\n",
        "                'https://www.github.com',\n",
        "                'https://www.example.com'\n",
        "            ],\n",
        "            'label': ['legitimate', 'legitimate', 'legitimate']\n",
        "        }\n",
        "        df = pd.DataFrame(sample_data)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in data collection: {e}\")\n",
        "    # Create fallback data\n",
        "    df = pd.DataFrame({\n",
        "        'url': ['https://www.google.com', 'https://www.example.com'],\n",
        "        'label': ['legitimate', 'legitimate']\n",
        "    })\n",
        "\n",
        "# Ensure we always have a DataFrame\n",
        "if df.empty:\n",
        "    print(\"‚ö†Ô∏è  Dataset is empty. Creating sample data...\")\n",
        "    df = pd.DataFrame({\n",
        "        'url': ['https://www.google.com', 'https://www.github.com'],\n",
        "        'label': ['legitimate', 'legitimate']\n",
        "    })\n",
        "\n",
        "print(f\"üéâ Final dataset shape: {df.shape}\")\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "# Display the data\n",
        "print(\"\\nüìä First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"‚úÖ Data collection completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "HqFZDArusMeq",
        "outputId": "9cbfc483-bb49-41c2-a54f-d9d4f5913ca4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data collection...\n",
            "Choose data source:\n",
            "1 - Upload files manually\n",
            "2 - Fetch data automatically from web\n",
            "Enter 1 or 2: 1\n",
            "üìÅ Please upload your CSV or Excel file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f609bea-8d3d-4fd0-a147-73194f3e29d5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7f609bea-8d3d-4fd0-a147-73194f3e29d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PS02_Training_set.zip to PS02_Training_set.zip\n",
            "Loading: PS02_Training_set.zip\n",
            "Skipping: PS02_Training_set.zip\n",
            "‚úÖ Upload complete. Shape: (0, 0)\n",
            "‚ö†Ô∏è  Dataset is empty. Creating sample data...\n",
            "üéâ Final dataset shape: (2, 2)\n",
            "Columns: ['url', 'label']\n",
            "\n",
            "üìä First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      url       label\n",
              "0  https://www.google.com  legitimate\n",
              "1  https://www.github.com  legitimate"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-488ccd74-9581-48ae-ae4f-3d79568697bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.google.com</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.github.com</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-488ccd74-9581-48ae-ae4f-3d79568697bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-488ccd74-9581-48ae-ae4f-3d79568697bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-488ccd74-9581-48ae-ae4f-3d79568697bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d5e6d901-b0aa-421d-a2fd-4e0b222c7f4f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5e6d901-b0aa-421d-a2fd-4e0b222c7f4f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d5e6d901-b0aa-421d-a2fd-4e0b222c7f4f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\u2705 Data collection completed successfully!\\\")\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"https://www.github.com\",\n          \"https://www.google.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"legitimate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data collection completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# üîç SIMPLE URL Column Detection\n",
        "# ==============================\n",
        "\n",
        "print(\"DataFrame columns:\", list(df.columns))\n",
        "print(\"DataFrame shape:\", df.shape)\n",
        "\n",
        "# Show first row to understand data structure\n",
        "print(\"\\nFirst row of data:\")\n",
        "print(df.iloc[0] if len(df) > 0 else \"Empty DataFrame\")\n",
        "\n",
        "# Simple detection - use first column that has URLs or let user choose\n",
        "URL_COLUMN = None\n",
        "\n",
        "# Try common column names\n",
        "common_url_columns = ['url', 'link', 'website', 'domain', 'Whitelisted Domains', 'URL', 'Website']\n",
        "for col in common_url_columns:\n",
        "    if col in df.columns:\n",
        "        URL_COLUMN = col\n",
        "        break\n",
        "\n",
        "# If not found, use first column\n",
        "if URL_COLUMN is None and len(df.columns) > 0:\n",
        "    URL_COLUMN = df.columns[0]\n",
        "    print(f\"‚ö†Ô∏è  Using first column as URL column: '{URL_COLUMN}'\")\n",
        "elif URL_COLUMN:\n",
        "    print(f\"‚úÖ Using detected URL column: '{URL_COLUMN}'\")\n",
        "else:\n",
        "    print(\"‚ùå No columns found in DataFrame\")\n",
        "\n",
        "print(f\"üéØ URL column: '{URL_COLUMN}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxkpbmANsSNa",
        "outputId": "8d0917d2-b72e-4954-f408-8705e53ac69a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame columns: ['url', 'label']\n",
            "DataFrame shape: (2, 2)\n",
            "\n",
            "First row of data:\n",
            "url      https://www.google.com\n",
            "label                legitimate\n",
            "Name: 0, dtype: object\n",
            "‚úÖ Using detected URL column: 'url'\n",
            "üéØ URL column: 'url'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# üöÄ TRANSFORMER FEATURE EXTRACTION\n",
        "# ==============================\n",
        "\n",
        "def extract_text_features_with_transformers(html_text, url):\n",
        "    \"\"\"Extract text features using transformers\"\"\"\n",
        "    features = {}\n",
        "\n",
        "    try:\n",
        "        if not html_text:\n",
        "            return get_default_text_features()\n",
        "\n",
        "        soup = BeautifulSoup(html_text, 'html.parser')\n",
        "\n",
        "        # Clean text\n",
        "        for script in soup([\"script\", \"style\", \"meta\", \"noscript\"]):\n",
        "            script.decompose()\n",
        "\n",
        "        title_text = soup.find('title')\n",
        "        title = title_text.get_text().strip() if title_text else \"\"\n",
        "        visible_text = ' '.join(soup.stripped_strings)\n",
        "        full_text = f\"{title} {visible_text}\"[:500]\n",
        "\n",
        "        # Check if we have real transformer models (not dummies)\n",
        "        if (full_text.strip() and\n",
        "            hasattr(TRANSFORMER_MODELS['text_tokenizer'], 'dummy') and\n",
        "            not TRANSFORMER_MODELS['text_tokenizer'].dummy):\n",
        "\n",
        "            # BERT embeddings\n",
        "            inputs = TRANSFORMER_MODELS['text_tokenizer'](full_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = TRANSFORMER_MODELS['text_model'](**inputs)\n",
        "\n",
        "            text_embedding = outputs.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "            features['text_embedding_mean'] = float(np.mean(text_embedding))\n",
        "            features['text_embedding_std'] = float(np.std(text_embedding))\n",
        "\n",
        "            # Sentence transformer\n",
        "            sentence_emb = TRANSFORMER_MODELS['sentence_model'].encode([full_text])[0]\n",
        "            features['sentence_embedding_mean'] = float(np.mean(sentence_emb))\n",
        "        else:\n",
        "            # Use dummy values if transformers didn't load properly\n",
        "            features['text_embedding_mean'] = 0.5\n",
        "            features['text_embedding_std'] = 0.1\n",
        "            features['sentence_embedding_mean'] = 0.5\n",
        "\n",
        "        # Text structure\n",
        "        features['text_length'] = len(visible_text)\n",
        "        features['title_length'] = len(title)\n",
        "        security_words = ['login','password','secure','bank','verify','account']\n",
        "        features['security_keyword_density'] = sum(1 for k in security_words if k in visible_text.lower()) / max(1, len(visible_text.split()))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Text feature error for {url}: {e}\")\n",
        "        features = get_default_text_features()\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_visual_features_with_transformers(url):\n",
        "    \"\"\"Extract visual features using transformers\"\"\"\n",
        "    features = {}\n",
        "\n",
        "    try:\n",
        "        # Try to get favicon\n",
        "        favicon_data = extract_favicon(url)\n",
        "        if favicon_data and 'image' in favicon_data:\n",
        "            image = favicon_data['image']\n",
        "\n",
        "            # Check if we have real transformer models\n",
        "            if (hasattr(TRANSFORMER_MODELS['image_processor'], 'dummy') and\n",
        "                not TRANSFORMER_MODELS['image_processor'].dummy):\n",
        "\n",
        "                inputs = TRANSFORMER_MODELS['image_processor'](images=image, return_tensors=\"pt\")\n",
        "                with torch.no_grad():\n",
        "                    outputs = TRANSFORMER_MODELS['image_model'](**inputs)\n",
        "\n",
        "                image_embeddings = outputs.last_hidden_state.mean(dim=1).numpy().flatten()\n",
        "                features['image_embedding_mean'] = float(np.mean(image_embeddings))\n",
        "                features['image_present'] = 1\n",
        "            else:\n",
        "                # Use dummy values\n",
        "                features['image_embedding_mean'] = 0.5\n",
        "                features['image_present'] = 1\n",
        "        else:\n",
        "            features = get_default_visual_features()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Visual feature error for {url}: {e}\")\n",
        "        features = get_default_visual_features()\n",
        "\n",
        "    return features\n",
        "\n",
        "# Keep all other helper functions the same as before\n",
        "def extract_favicon(url):\n",
        "    \"\"\"Extract favicon from URL\"\"\"\n",
        "    try:\n",
        "        if not url.startswith('http'):\n",
        "            test_url = 'http://' + url\n",
        "        else:\n",
        "            test_url = url\n",
        "\n",
        "        response = requests.get(test_url, timeout=5, verify=False)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        icon_link = soup.find('link', rel=lambda x: x and 'icon' in x.lower() if x else False)\n",
        "        if icon_link and icon_link.get('href'):\n",
        "            icon_url = urljoin(test_url, icon_link['href'])\n",
        "        else:\n",
        "            icon_url = urljoin(test_url, '/favicon.ico')\n",
        "\n",
        "        icon_response = requests.get(icon_url, timeout=5, verify=False)\n",
        "        if icon_response.status_code == 200:\n",
        "            image = Image.open(BytesIO(icon_response.content)).convert('RGB')\n",
        "            image = image.resize((224, 224))\n",
        "            return {'image': image}\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "def get_default_text_features():\n",
        "    return {\n",
        "        'text_embedding_mean': 0.0, 'text_embedding_std': 0.0,\n",
        "        'sentence_embedding_mean': 0.0, 'text_length': 0,\n",
        "        'title_length': 0, 'security_keyword_density': 0.0\n",
        "    }\n",
        "\n",
        "def get_default_visual_features():\n",
        "    return {'image_embedding_mean': 0.0, 'image_present': 0}\n",
        "\n",
        "def safe_request_get(url, timeout=6):\n",
        "    try:\n",
        "        return requests.get(\"http://\"+url if not url.startswith(\"http\") else url, timeout=timeout, allow_redirects=True, verify=False)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def fetch_page(url):\n",
        "    r = safe_request_get(url)\n",
        "    return (r, r.text) if r else (None, None)\n",
        "\n",
        "def enhanced_logo_similarity(url):\n",
        "    visual_features = extract_visual_features_with_transformers(url)\n",
        "    return visual_features.get('image_embedding_mean', 0.0)\n",
        "\n",
        "def enhanced_text_similarity(url):\n",
        "    try:\n",
        "        resp, html = fetch_page(url)\n",
        "        if not html: return 0.0\n",
        "        text_features = extract_text_features_with_transformers(html, url)\n",
        "        return text_features.get('sentence_embedding_mean', 0.0)\n",
        "    except:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "RyL0HSttJaSL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# üîß EXISTING FEATURE FUNCTIONS\n",
        "# ==============================\n",
        "\n",
        "# Lexical features\n",
        "def url_length(url): return len(url) if isinstance(url,str) else np.nan\n",
        "def count_chars(url,ch): return url.count(ch) if isinstance(url,str) else 0\n",
        "def count_digits(url): return sum(c.isdigit() for c in str(url))\n",
        "def count_letters(url): return sum(c.isalpha() for c in str(url))\n",
        "def count_hyphens(url): return count_chars(url,'-')\n",
        "def count_dots(url): return count_chars(url,'.')\n",
        "def count_special_chars(url): return len(re.findall(r'[^A-Za-z0-9]', str(url)))\n",
        "\n",
        "def shannon_entropy(s):\n",
        "    s = str(s)\n",
        "    if len(s) == 0: return 0.0\n",
        "    prob = [float(s.count(c))/len(s) for c in dict.fromkeys(list(s))]\n",
        "    return -sum([p*math.log(p,2) for p in prob])\n",
        "\n",
        "def has_suspicious_keyword(url):\n",
        "    suspicious = ['login','signin','secure','update','verify','account','bank','ebay','paypal','click']\n",
        "    url = str(url).lower()\n",
        "    return int(any(k in url for k in suspicious))\n",
        "\n",
        "def num_subdomains(url):\n",
        "    try:\n",
        "        ext = tldextract.extract(url)\n",
        "        return len(ext.subdomain.split('.')) if ext.subdomain else 0\n",
        "    except: return 0\n",
        "\n",
        "def top_domain_under_public_suffix(url):\n",
        "    try: return tldextract.extract(url).domain\n",
        "    except: return None\n",
        "\n",
        "def tld_suffix(url):\n",
        "    try: return tldextract.extract(url).suffix\n",
        "    except: return ''\n",
        "\n",
        "# DNS/IP Functions\n",
        "_rdap_cache = {}\n",
        "\n",
        "def _query_json(url, timeout=10):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=timeout, headers={\"User-Agent\":\"feature-extractor/1.0\"})\n",
        "        r.raise_for_status()\n",
        "        return r.json()\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def get_asn_info(ip):\n",
        "    if not ip:\n",
        "        return {\"asn\": None, \"rir\": None, \"name\": None, \"country\": None, \"error\": \"no ip\"}\n",
        "    if ip in _rdap_cache:\n",
        "        return _rdap_cache[ip]\n",
        "\n",
        "    try:\n",
        "        iana_url = f\"https://rdap.iana.org/ip/{ip}\"\n",
        "        iana_json = _query_json(iana_url)\n",
        "        if not iana_json:\n",
        "            out = {\"asn\": None, \"rir\": None, \"name\": None, \"country\": None, \"error\": \"iana lookup failed\"}\n",
        "            _rdap_cache[ip] = out\n",
        "            return out\n",
        "\n",
        "        links = iana_json.get(\"links\") or []\n",
        "        if not links:\n",
        "            out = {\"asn\": None, \"rir\": None, \"name\": None, \"country\": None, \"error\": \"no rdap links from iana\"}\n",
        "            _rdap_cache[ip] = out\n",
        "            return out\n",
        "\n",
        "        last_exc = None\n",
        "        for link in links:\n",
        "            rdap_url = link.get(\"href\")\n",
        "            if not rdap_url:\n",
        "                continue\n",
        "\n",
        "            rdap_json = _query_json(rdap_url)\n",
        "            if not rdap_json:\n",
        "                try_url = rdap_url\n",
        "                if not try_url.endswith(\"/\"):\n",
        "                    try_url = try_url + \"/\"\n",
        "                try_url = urljoin(try_url, f\"ip/{ip}\")\n",
        "                rdap_json = _query_json(try_url)\n",
        "                if not rdap_json:\n",
        "                    last_exc = f\"failed rdap at {rdap_url}\"\n",
        "                    continue\n",
        "\n",
        "            asn = None\n",
        "            name = rdap_json.get(\"name\") or rdap_json.get(\"handle\")\n",
        "            country = rdap_json.get(\"country\") or None\n",
        "\n",
        "            if \"asn\" in rdap_json and rdap_json[\"asn\"]:\n",
        "                asn = str(rdap_json[\"asn\"])\n",
        "\n",
        "            network = rdap_json.get(\"network\") or rdap_json.get(\"object\") or rdap_json\n",
        "            if isinstance(network, dict):\n",
        "                handle = network.get(\"handle\") or network.get(\"name\")\n",
        "                if handle and not asn:\n",
        "                    asn = handle\n",
        "\n",
        "            out = {\"asn\": asn, \"rir\": rdap_url, \"name\": name, \"country\": country, \"error\": None}\n",
        "            _rdap_cache[ip] = out\n",
        "            return out\n",
        "\n",
        "        out = {\"asn\": None, \"rir\": None, \"name\": None, \"country\": None, \"error\": last_exc or \"rdap failed\"}\n",
        "        _rdap_cache[ip] = out\n",
        "        return out\n",
        "\n",
        "    except Exception as e:\n",
        "        out = {\"asn\": None, \"rir\": None, \"name\": None, \"country\": None, \"error\": str(e)}\n",
        "        _rdap_cache[ip] = out\n",
        "        return out\n",
        "\n",
        "def resolve_ip(domain):\n",
        "    try: return socket.gethostbyname(domain)\n",
        "    except: return None\n",
        "\n",
        "def ip_whois_country(ip):\n",
        "    try:\n",
        "        obj=IPWhois(ip)\n",
        "        res=obj.lookup_rdap(depth=1)\n",
        "        return res.get('network',{}).get('country')\n",
        "    except: return None\n",
        "\n",
        "def ssl_valid(domain):\n",
        "    try:\n",
        "        ctx=ssl.create_default_context()\n",
        "        with ctx.wrap_socket(socket.socket(),server_hostname=domain) as s:\n",
        "            s.settimeout(4.0)\n",
        "            s.connect((domain,443))\n",
        "            cert=s.getpeercert()\n",
        "            return 1 if cert else 0\n",
        "    except: return 0\n",
        "\n",
        "def ssl_days_remaining(domain):\n",
        "    try:\n",
        "        ctx=ssl.create_default_context()\n",
        "        with ctx.wrap_socket(socket.socket(),server_hostname=domain) as s:\n",
        "            s.settimeout(4.0)\n",
        "            s.connect((domain,443))\n",
        "            cert=s.getpeercert()\n",
        "        if cert:\n",
        "            not_after=cert.get('notAfter')\n",
        "            expire_dt=datetime.strptime(not_after,'%b %d %H:%M:%S %Y %Z')\n",
        "            return (expire_dt-datetime.now()).days\n",
        "    except: return np.nan\n",
        "\n",
        "def safe_request_get(url, timeout=6):\n",
        "    try:\n",
        "        return requests.get(\"http://\"+url if not url.startswith(\"http\") else url, timeout=timeout, allow_redirects=True, verify=False)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def fetch_page(url):\n",
        "    r = safe_request_get(url)\n",
        "    return (r, r.text) if r else (None, None)\n",
        "\n",
        "def count_meta_tags(html):\n",
        "    try: return len(BeautifulSoup(html,'html.parser').find_all('meta'))\n",
        "    except: return 0\n",
        "\n",
        "def has_iframe(html):\n",
        "    try: return int(bool(BeautifulSoup(html,'html.parser').find('iframe')))\n",
        "    except: return 0\n",
        "\n",
        "def count_forms(html):\n",
        "    try: return len(BeautifulSoup(html,'html.parser').find_all('form'))\n",
        "    except: return 0\n",
        "\n",
        "def has_password_input(html):\n",
        "    try:\n",
        "        for inp in BeautifulSoup(html,'html.parser').find_all('input',attrs={'type':True}):\n",
        "            if inp.get('type','').lower()=='password': return 1\n",
        "        return 0\n",
        "    except: return 0\n",
        "\n",
        "def count_external_links(html, base_domain):\n",
        "    try:\n",
        "        anchors=BeautifulSoup(html,'html.parser').find_all('a',href=True)\n",
        "        return sum(1 for a in anchors if a['href'].startswith('http') and base_domain not in a['href'])\n",
        "    except: return 0\n",
        "\n",
        "def favicon_hash(url):\n",
        "    try:\n",
        "        r=safe_request_get(url)\n",
        "        if not r: return None\n",
        "        soup=BeautifulSoup(r.text,'html.parser')\n",
        "        icon=soup.find('link',rel=lambda x: x and 'icon' in x.lower())\n",
        "        if icon and icon.get('href'):\n",
        "            icon_url=urljoin(url,icon['href'])\n",
        "            ir=safe_request_get(icon_url)\n",
        "            if ir and ir.content:\n",
        "                img=Image.open(io.BytesIO(ir.content)).convert('RGB')\n",
        "                return str(imagehash.average_hash(img))\n",
        "    except: return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "z57Izc9gJ20W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# üöÄ SIMPLE TRANSFORMER FEATURES (FALLBACK INCLUDED)\n",
        "# ==============================\n",
        "\n",
        "def extract_simple_text_features(html_text, url):\n",
        "    \"\"\"Simple text features that work even without transformers\"\"\"\n",
        "    features = {}\n",
        "\n",
        "    try:\n",
        "        if not html_text:\n",
        "            return {'text_length': 0, 'title_length': 0, 'security_score': 0.0}\n",
        "\n",
        "        soup = BeautifulSoup(html_text, 'html.parser')\n",
        "\n",
        "        # Clean text\n",
        "        for script in soup([\"script\", \"style\", \"meta\", \"noscript\"]):\n",
        "            script.decompose()\n",
        "\n",
        "        # Extract basic text features\n",
        "        title_text = soup.find('title')\n",
        "        title = title_text.get_text().strip() if title_text else \"\"\n",
        "        visible_text = ' '.join(soup.stripped_strings)\n",
        "\n",
        "        # Basic features\n",
        "        features['text_length'] = len(visible_text)\n",
        "        features['title_length'] = len(title)\n",
        "\n",
        "        # Security keywords (simple version)\n",
        "        security_keywords = ['login', 'password', 'secure', 'verify', 'account', 'bank', 'signin']\n",
        "        found_keywords = sum(1 for keyword in security_keywords if keyword in visible_text.lower())\n",
        "        features['security_score'] = found_keywords / len(security_keywords) if security_keywords else 0.0\n",
        "\n",
        "        # Try transformer features if available\n",
        "        if 'TRANSFORMER_MODELS' in globals() and hasattr(TRANSFORMER_MODELS.get('text_model', None), 'dummy'):\n",
        "            if not TRANSFORMER_MODELS['text_model'].dummy:\n",
        "                # Real transformers available\n",
        "                full_text = f\"{title} {visible_text}\"[:500]\n",
        "                inputs = TRANSFORMER_MODELS['text_tokenizer'](full_text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "                with torch.no_grad():\n",
        "                    outputs = TRANSFORMER_MODELS['text_model'](**inputs)\n",
        "                text_embedding = outputs.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "                features['text_embedding_mean'] = float(np.mean(text_embedding))\n",
        "                features['sentence_embedding'] = float(np.mean(TRANSFORMER_MODELS['sentence_model'].encode([full_text])[0]))\n",
        "            else:\n",
        "                # Dummy transformers - use simple alternatives\n",
        "                features['text_embedding_mean'] = len(visible_text) / 1000.0  # Simple proxy\n",
        "                features['sentence_embedding'] = features['security_score']\n",
        "        else:\n",
        "            # No transformers available\n",
        "            features['text_embedding_mean'] = len(visible_text) / 1000.0\n",
        "            features['sentence_embedding'] = features['security_score']\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Text feature error for {url}: {e}\")\n",
        "        features = {'text_length': 0, 'title_length': 0, 'security_score': 0.0, 'text_embedding_mean': 0.0, 'sentence_embedding': 0.0}\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_simple_visual_features(url):\n",
        "    \"\"\"Simple visual features that work even without transformers\"\"\"\n",
        "    features = {}\n",
        "\n",
        "    try:\n",
        "        # Try to get favicon\n",
        "        favicon_data = extract_favicon(url)\n",
        "        if favicon_data and 'image' in favicon_data:\n",
        "            features['image_present'] = 1\n",
        "\n",
        "            # Try transformer features if available\n",
        "            if 'TRANSFORMER_MODELS' in globals() and hasattr(TRANSFORMER_MODELS.get('image_model', None), 'dummy'):\n",
        "                if not TRANSFORMER_MODELS['image_model'].dummy:\n",
        "                    # Real transformers available\n",
        "                    inputs = TRANSFORMER_MODELS['image_processor'](images=favicon_data['image'], return_tensors=\"pt\")\n",
        "                    with torch.no_grad():\n",
        "                        outputs = TRANSFORMER_MODELS['image_model'](**inputs)\n",
        "                    image_embeddings = outputs.last_hidden_state.mean(dim=1).numpy().flatten()\n",
        "                    features['image_embedding'] = float(np.mean(image_embeddings))\n",
        "                else:\n",
        "                    # Dummy transformers - use simple hash\n",
        "                    features['image_embedding'] = hash(str(favicon_data['image'].size)) % 100 / 100.0\n",
        "            else:\n",
        "                # No transformers - use simple hash\n",
        "                features['image_embedding'] = hash(str(favicon_data['image'].size)) % 100 / 100.0\n",
        "        else:\n",
        "            features = {'image_present': 0, 'image_embedding': 0.0}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Visual feature error for {url}: {e}\")\n",
        "        features = {'image_present': 0, 'image_embedding': 0.0}\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_favicon(url):\n",
        "    \"\"\"Extract favicon from URL\"\"\"\n",
        "    try:\n",
        "        if not url.startswith('http'):\n",
        "            test_url = 'http://' + url\n",
        "        else:\n",
        "            test_url = url\n",
        "\n",
        "        response = requests.get(test_url, timeout=5, verify=False)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        icon_link = soup.find('link', rel=lambda x: x and 'icon' in x.lower() if x else False)\n",
        "        if icon_link and icon_link.get('href'):\n",
        "            icon_url = urljoin(test_url, icon_link['href'])\n",
        "        else:\n",
        "            icon_url = urljoin(test_url, '/favicon.ico')\n",
        "\n",
        "        icon_response = requests.get(icon_url, timeout=5, verify=False)\n",
        "        if icon_response.status_code == 200:\n",
        "            image = Image.open(io.BytesIO(icon_response.content)).convert('RGB')\n",
        "            image = image.resize((224, 224))\n",
        "            return {'image': image}\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# Enhanced similarity functions (fallback included)\n",
        "def enhanced_logo_similarity(url):\n",
        "    visual_features = extract_simple_visual_features(url)\n",
        "    return visual_features.get('image_embedding', 0.0)\n",
        "\n",
        "def enhanced_text_similarity(url):\n",
        "    try:\n",
        "        resp, html = fetch_page(url)\n",
        "        if not html: return 0.0\n",
        "        text_features = extract_simple_text_features(html, url)\n",
        "        return text_features.get('sentence_embedding', 0.0)\n",
        "    except:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "d-XNtcodKMxF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- MAIN PIPELINE (TRANSFORMER OR FALLBACK) ---\n",
        "OUTPUT_PATH = \"final_dataset.csv\"\n",
        "\n",
        "print(\"Starting feature extraction pipeline...\")\n",
        "print(f\"Processing {len(df)} URLs\")\n",
        "rows = []\n",
        "\n",
        "for i, raw_url in enumerate(df[URL_COLUMN].astype(str)):\n",
        "    row = {'url': raw_url.strip()}\n",
        "    url = row['url']\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"Processing {i+1}/{len(df)}: {url}\")\n",
        "\n",
        "    try:\n",
        "        # --- Lexical Features ---\n",
        "        row['url_length'] = url_length(url)\n",
        "        row['num_dots'] = count_dots(url)\n",
        "        row['num_hyphens'] = count_hyphens(url)\n",
        "        row['num_digits'] = count_digits(url)\n",
        "        row['num_letters'] = count_letters(url)\n",
        "        row['num_special_chars'] = count_special_chars(url)\n",
        "        row['entropy'] = shannon_entropy(url)\n",
        "        row['suspicious_keyword'] = has_suspicious_keyword(url)\n",
        "        row['num_subdomains'] = num_subdomains(url)\n",
        "        domain = top_domain_under_public_suffix(url)\n",
        "        row['top_domain_under_public_suffix'] = domain\n",
        "        row['tld'] = tld_suffix(url)\n",
        "\n",
        "        # --- DNS/IP Features ---\n",
        "        ip = resolve_ip(domain) if domain else None\n",
        "        row['ip'] = ip\n",
        "        row['ip_country'] = ip_whois_country(ip) if ip else None\n",
        "\n",
        "        # ASN lookup\n",
        "        asn_info = get_asn_info(ip) if ip else {\"asn\": None, \"country\": None}\n",
        "        row['asn'] = asn_info.get('asn')\n",
        "        row['asn_country'] = asn_info.get('country')\n",
        "\n",
        "        # --- SSL Features ---\n",
        "        row['ssl_valid'] = ssl_valid(domain) if domain else 0\n",
        "        row['ssl_days_remaining'] = ssl_days_remaining(domain) if domain else np.nan\n",
        "\n",
        "        # --- HTTP/Content Features ---\n",
        "        resp, html = fetch_page(url)\n",
        "        row['status_code'] = resp.status_code if resp else None\n",
        "        row['content_length'] = len(resp.content) if resp and resp.content else 0\n",
        "\n",
        "        # Traditional content features\n",
        "        row['meta_tags'] = count_meta_tags(html) if html else 0\n",
        "        row['has_iframe'] = has_iframe(html) if html else 0\n",
        "        row['external_links'] = count_external_links(html, domain) if html and domain else 0\n",
        "        row['has_password_input'] = has_password_input(html) if html else 0\n",
        "        row['form_count'] = count_forms(html) if html else 0\n",
        "        row['favicon_hash'] = favicon_hash(url)\n",
        "\n",
        "        # --- TRANSFORMER/FALLBACK FEATURES ---\n",
        "        if html:\n",
        "            text_features = extract_simple_text_features(html, url)\n",
        "            row.update(text_features)\n",
        "\n",
        "            visual_features = extract_simple_visual_features(url)\n",
        "            row.update(visual_features)\n",
        "        else:\n",
        "            # Default values if no HTML\n",
        "            row.update({'text_length': 0, 'title_length': 0, 'security_score': 0.0,\n",
        "                       'text_embedding_mean': 0.0, 'sentence_embedding': 0.0,\n",
        "                       'image_present': 0, 'image_embedding': 0.0})\n",
        "\n",
        "        # Enhanced similarity\n",
        "        row['logo_similarity'] = enhanced_logo_similarity(url)\n",
        "        row['text_similarity'] = enhanced_text_similarity(url)\n",
        "\n",
        "        # Hashes\n",
        "        row['sha1'] = hashlib.sha1(url.encode()).hexdigest()\n",
        "        row['md5'] = hashlib.md5(url.encode()).hexdigest()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {e}\")\n",
        "        # Add default values for all expected columns\n",
        "        default_features = {\n",
        "            'text_length': 0, 'title_length': 0, 'security_score': 0.0,\n",
        "            'text_embedding_mean': 0.0, 'sentence_embedding': 0.0,\n",
        "            'image_present': 0, 'image_embedding': 0.0,\n",
        "            'logo_similarity': 0.0, 'text_similarity': 0.0\n",
        "        }\n",
        "        row.update(default_features)\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "# Save results\n",
        "features_df = pd.DataFrame(rows)\n",
        "final_df = pd.concat([df.reset_index(drop=True), features_df.reset_index(drop=True)], axis=1)\n",
        "final_df.to_csv(OUTPUT_PATH, index=False)\n",
        "print(f\"‚úÖ Feature extraction complete!\")\n",
        "print(f\"üìä Final dataset shape: {final_df.shape}\")\n",
        "print(f\"üíæ Saved to: {OUTPUT_PATH}\")\n",
        "\n",
        "# Show results\n",
        "print(\"\\nFirst 3 rows with new features:\")\n",
        "final_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "0LSqcD36KZc1",
        "outputId": "4764a981-4fd4-4bc2-e1ad-9ab7eb31bf5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting feature extraction pipeline...\n",
            "Processing 2 URLs\n",
            "Error processing https://www.google.com: name 're' is not defined\n",
            "Error processing https://www.github.com: name 're' is not defined\n",
            "‚úÖ Feature extraction complete!\n",
            "üìä Final dataset shape: (2, 17)\n",
            "üíæ Saved to: final_dataset.csv\n",
            "\n",
            "First 3 rows with new features:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      url       label                     url  url_length  \\\n",
              "0  https://www.google.com  legitimate  https://www.google.com          22   \n",
              "1  https://www.github.com  legitimate  https://www.github.com          22   \n",
              "\n",
              "   num_dots  num_hyphens  num_digits  num_letters  text_length  title_length  \\\n",
              "0         2            0           0           17            0             0   \n",
              "1         2            0           0           17            0             0   \n",
              "\n",
              "   security_score  text_embedding_mean  sentence_embedding  image_present  \\\n",
              "0             0.0                  0.0                 0.0              0   \n",
              "1             0.0                  0.0                 0.0              0   \n",
              "\n",
              "   image_embedding  logo_similarity  text_similarity  \n",
              "0              0.0              0.0              0.0  \n",
              "1              0.0              0.0              0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b87e8f85-d30a-43a1-8e3d-e70e428923e1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>label</th>\n",
              "      <th>url</th>\n",
              "      <th>url_length</th>\n",
              "      <th>num_dots</th>\n",
              "      <th>num_hyphens</th>\n",
              "      <th>num_digits</th>\n",
              "      <th>num_letters</th>\n",
              "      <th>text_length</th>\n",
              "      <th>title_length</th>\n",
              "      <th>security_score</th>\n",
              "      <th>text_embedding_mean</th>\n",
              "      <th>sentence_embedding</th>\n",
              "      <th>image_present</th>\n",
              "      <th>image_embedding</th>\n",
              "      <th>logo_similarity</th>\n",
              "      <th>text_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.google.com</td>\n",
              "      <td>legitimate</td>\n",
              "      <td>https://www.google.com</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.github.com</td>\n",
              "      <td>legitimate</td>\n",
              "      <td>https://www.github.com</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b87e8f85-d30a-43a1-8e3d-e70e428923e1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b87e8f85-d30a-43a1-8e3d-e70e428923e1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b87e8f85-d30a-43a1-8e3d-e70e428923e1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8f198da9-3d4d-4768-8370-1fadac61fef8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f198da9-3d4d-4768-8370-1fadac61fef8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8f198da9-3d4d-4768-8370-1fadac61fef8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_df",
              "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"https://www.github.com\",\n          \"https://www.google.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"legitimate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"https://www.github.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 22,\n        \"max\": 22,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_dots\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 2,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_hyphens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_digits\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_letters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 17,\n        \"max\": 17,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"security_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_embedding_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_embedding\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_present\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_embedding\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logo_similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the final dataset\n",
        "from google.colab import files\n",
        "files.download(OUTPUT_PATH)\n",
        "print(\"üì• File download initiated!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cSQqzmMNKf_l",
        "outputId": "9ac2d98f-20be-4f8c-fa60-c535f9ebf2db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_395519bf-f3b5-4c0d-adf2-c02b685f930b\", \"final_dataset.csv\", 408)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• File download initiated!\n"
          ]
        }
      ]
    }
  ]
}